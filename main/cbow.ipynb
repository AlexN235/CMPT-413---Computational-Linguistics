{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "cbow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XPZd32M_4Zk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3ac33a2-a543-41c8-b5cc-a7c82dfb1079"
      },
      "source": [
        "################################################################################\r\n",
        "# Runs the word2vec:cbow model on a subset of the yelp review dataset and\r\n",
        "# reports back a score.  \r\n",
        "# \r\n",
        "# Current dataset was created using yelp_data_extraction.py\r\n",
        "# \r\n",
        "# The full data set can be found at https://www.yelp.com/dataset.\r\n",
        "################################################################################\r\n",
        "\r\n",
        "# Unzip data.zip if data folder does not exist.\r\n",
        "!unzip data.zip"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "replace data/review500-1-3-5.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: data/review500-1-3-5.json  \n",
            "  inflating: data/review500-1-5.json  \n",
            "  inflating: data/review500-2-4.json  \n",
            "  inflating: data/review500-3.json   \n",
            "  inflating: data/review500-all.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlqXyZTu4wsG"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from word2vec import Word2vec\n",
        "import word2vec\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWRdB0zJ4wsS",
        "outputId": "d608924a-c140-49f0-9555-bfb1cc5e6139"
      },
      "source": [
        "# Get data from json file and initialize cbow.\n",
        "corpus = \"data/review500-all.json\"\n",
        "cbow = Word2vec(corpus_name=corpus,learning_rate=0.75, test_len=100) # test_index is the max index for the test set.\n",
        "W1, W2, loss = cbow.run()\n",
        "\n",
        "print('Training size:', len(cbow.corpus) - cbow.test)\n",
        "print('Testing size:', cbow.test)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training size: 400\n",
            "Testing size: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A568E0yl4wsV"
      },
      "source": [
        "def rating_to_score(x):\n",
        "    if x > 3:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP0Oqvrj4wsW"
      },
      "source": [
        "# Get rating and prediction.\n",
        "rating = [rating_to_score(x) for x in cbow.test_rating]\n",
        "pred = word2vec.get_predictions(cbow.test_corpus, cbow, W1, W2)\n",
        "y = rating\n",
        "X = pred\n",
        "\n",
        "# Train based on predictions created from model.\n",
        "x_train,x_test,y_train,y_test = train_test_split(X, y, test_size=0.25,random_state=101)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "0-E7_R-A4wsY"
      },
      "source": [
        "# Using an multilayer perceptron classifier to score the baseline Tfidf score\n",
        "mlp = MLPClassifier()\n",
        "mlp.fit(x_train, y_train)\n",
        "predict_mlp = mlp.predict(x_test)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "9dkFR-Ai4wsa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a17cd20-00bc-4afb-880d-4348f5a5a0fe"
      },
      "source": [
        "# Print Results/Score\n",
        "print(classification_report(y_test, predict_mlp))\n",
        "print(\"Score:\",round(accuracy_score(y_test,predict_mlp)*100,2))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         6\n",
            "           1       0.76      1.00      0.86        19\n",
            "\n",
            "    accuracy                           0.76        25\n",
            "   macro avg       0.38      0.50      0.43        25\n",
            "weighted avg       0.58      0.76      0.66        25\n",
            "\n",
            "Score: 76.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}